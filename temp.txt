\subsubsection{Конфигурация бенчмарка и метрики оценки}
\label{retrieval-bench-eval}

% slava checked
Все отзывы из набора данных для бенчмарка были предварительно преобразованы в векторные представления (эмбеддинги) с использованием исследуемых моделей и загружены в \textit{Qdrant}. В процессе оценки текст запроса также переводился в эмбеддинг~--- при этом использовались соответствующие модели в зависимости от конкретной стратегии поиска (о чём подробнее рассказывается в следующих разделах). Далее система возвращала $K$ наиболее релевантных отзывов или заведений в соответствии с выбранным алгоритмом.

% slava checked
Качество поиска оценивалось с помощью метрики \textbf{Mean Average Precision at K (MAP@K)}, которая широко применяется в задачах ранжированного поиска. Расчёт проводился для значений $K = \{1, 3, 5, 20\}$, что позволяло охарактеризовать как точность верхних позиций, так и общее качество выдачи.

% slava checked
Для каждой комбинации модели и метода фиксировалось общее время, затраченное на выполнение всего бенчмарка, включая как инициализацию моделей, так и сам процесс поиска. Все модели запускались локально на машине с графическим процессором \textit{NVIDIA~RTX~2060} с $6$~ГБ видеопамяти и $64$~ГБ оперативной памяти.

% slava checked
Полученные результаты усреднялись по всем тестовым запросам и использовались для анализа точности и вычислительной эффективности каждого подхода. Такие данные критически важны для оценки пригодности решений для интерактивных систем реального времени.

\subsection{Embeddings}
\label{embedding-models}

% slava checked
В данном разделе рассматриваются основные подходы к семантическому поиску, применяемые в современных системах извлечения текстов на русском языке. Особое внимание уделяется плотным моделям (dense models), как специализированным для русского языка, так и мультиязычным, а также разреженным (sparse) методам, таким как BM25. Кроме того, рассматриваются также модели позднего взаимодействия (late interaction), такие как ColBERT, демонстрирующие высокую эффективность за счёт детального сопоставления токенов между запросом и документом.

\subsubsection{Dense models}
\label{dense-models}

% slava checked
Для получения эмбеддингов пользовательских запросов и отзывов в системе использовались различные предобученные языковые модели, относящиеся к классу dense. Такие модели преобразуют текст в компактные векторы фиксированной размерности, представленные числами с плавающей точкой.

% slava checked
Dense-эмбеддинги представляют собой непрерывные векторы низкой размерности, отражающие семантическое содержание текста. В отличие от традиционных разреженных подходов (таких как TF-IDF или мешок слов --- bag-of-words), основанных на поверхностном совпадении слов или токенов, dense-модели обучаются на больших объёмах текстов и способны улавливать глубокие лингвистические и контекстуальные зависимости между словами, предложениями и текстами.

% slava checked
Использование dense-эмбеддингов особенно эффективно в задачах семантического поиска, где требуется сопоставление текстов на уровне смысла, а не лишь по лексическому совпадению. Это критично в реальных пользовательских сценариях, когда одна и та же мысль может быть выражена множеством различных формулировок, особенно в неформальных пользовательских отзывах.

% slava checked
\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{img/mteb-website.png}
\caption{MTEB benchmark}
\label{fig:mteb-bench}
\end{figure}

% kizaru checked
Векторные представления запросов и документов сравниваются между собой с помощью метрик семантической близости, таких как косинусное расстояние, что позволяет находить наиболее релевантные элементы в базе по смыслу.

% slava checked
Для генерации dense-эмбеддингов как для отзывов, так и для запросов использовалась библиотека SentenceTransformers~\cite{reimers-2019-sentence-bert}, позволяющая загружать и использовать разнообразные модели из Hugging Face.
В рамках проекта отбор моделей осуществлялся по следующим критериям:

% slava checked
\begin{samepage}
\begin{itemize}
\item высокая производительность в бенчмарке \textbf{Massive Text Embedding Benchmark (MTEB)}~\cite{muennighoff2022mteb}~\cite{enevoldsen2025mmtebmassivemultilingualtext} --- масштабном сравнении ведущих моделей текстовых эмбеддингов на множестве датасетов (см. иллюстрацию на рисунке~\ref{fig:mteb-bench}) --- а также его русскоязычном подразделе \textbf{RuMTEB}\cite{snegirev2025russianfocusedembeddersexplorationrumteb} ;
\item поддержка русского языка: либо специализированные модели для русского, либо мультиязычные с его полноценной поддержкой;
\item размер модели --- не более $600$ миллионов параметров, что позволяло запускать их на локальной машине с $6$~GB GPU и $64$~ГБ RAM без необходимости использования серверной инфраструктуры.
\end{itemize}
\end{samepage}


% slava checked
Выбранные модели и их основные характеристики отражены в таблице \ref{table:dense-models}. Были отобраны как мультиязычные модели (например, \texttt{multilingual-e5-large}, \texttt{distiluse-base-multilingual-cased}), так и модели, специально обученные для русского языка (например, \texttt{ru-en-RoSBERTa}, \texttt{ai-forever/sbert\_large\_nlu\_ru}). Размерность эмбеддингов варьировалась от 312 до 1024 в зависимости от архитектуры и использовалась как для кодирования запросов, так и для отзывов.

% slava checked
В большинстве случаев тексты запросов и документов (отзывов) подавались в модель в исходном виде. Однако некоторые архитектуры (например, \texttt{intfloat-multilingual-e5-*}) требовали добавления специальных префиксов: \textit{query:} для пользовательского запроса и \textit{passage:} для документа. Подобный подход использовался и в моделях \texttt{ru-en-RoSBERTa} и \texttt{BERTA}, где применялись префиксы \textit{search\_query:} и \textit{search\_document:} соответственно.

\subsubsection{Sparse models}
% https://qdrant.tech/articles/sparse-vectors/

% slava checked
Помимо моделей, создающих dense-эмбеддинги, существуют и подходы, основанные на разреженных эмбеддингах (sparse embeddings). Такие модели стремятся сохранить интерпретируемость представления текста, фокусируясь на значимых словах и терминах. Одним из наиболее известных и широко применяемых методов, работающих с разреженными представлениями, является \texttt{BM25}~\cite{10.1561/1500000019}.

% slava checked
\texttt{BM25} --- это классический алгоритм полнотекстового поиска, основанный на вероятностной модели ранжирования документов. Он оценивает релевантность документа запросу, принимая во внимание частоту встречаемости ключевых слов и длину текста. Благодаря простоте и высокой вычислительной эффективности, \texttt{BM25} остаётся популярным выбором в системах, где критически важна оперативность ответа.

% slava checked
Однако у \texttt{BM25} есть и ограничения. Алгоритм работает на уровне точного совпадения слов, что делает его менее эффективным при наличии синонимов, переформулировок запросов или необходимости учитывать контекст. Он не учитывает семантическое значение слов и опирается только на их частотные характеристики, а также требует предварительного сбора статистики по всему корпусу документов.

% slava checked
Комбинированные подходы, такие как модель \texttt{SPLADE} (Sparse Lexical and Expansion Model)~\cite{formal2021spladesparselexicalexpansion}, объединяют сильные стороны плотных и разреженных векторных представлений: они учитывают контекст с помощью трансформеров, но при этом сохраняют интерпретируемость и совместимость с классическими поисковыми механизмами. Однако на момент проведения экспериментов не было доступных полноценных реализаций \texttt{SPLADE}, обученных на русскоязычных данных.

% slava checked
Разреженные подходы к векторному представлению текста используют векторы, в которых каждое измерение соответствует конкретному слову или подслову. В отличие от плотных векторов, содержащих сотни ненулевых значений (например, $dense = [0.2, 0.3, 0.5, 0.7, ...]$), разреженные векторы хранят только значимые признаки, где большинство элементов равны нулю (например, $sparse = [{331\!: 0.5}, {14136\!: 0.7}]$). Это позволяет значительно экономить память за счёт хранения только непустых значений.

% slava checked
В рамках нашего дипломного проекта мы использовали алгоритм \texttt{BM25} на основе реализации, предоставленной библиотекой \textit{fastembed}~\cite{fastembed2025}, разработанной командой \textit{Qdrant}.

\subsubsection{Late interaction models}
\label{late-interaction-models}
% https://qdrant.tech/documentation/fastembed/fastembed-colbert/
% https://qdrant.tech/documentation/concepts/vectors/?q=MultiVectorComparator.MAX_SIM#multivectors
% COLBERT
% Долго работает
% Вектор-матрица
% Поддерживается в Qdrant и есть модель мультиязычная
% Делаем эмбеддинги с помощью FastEmbed
% jinaai/jina-colbert-v2

% slava checked
\texttt{ColBERT}~\cite{khattab2020colbertefficienteffectivepassage} --- это модель векторизации, которая создаёт матричное (мультивекторное) представление входного текста, генерируя по одному вектору на каждый токен. Такой подход позволяет \texttt{ColBERT} улавливать более тонкие смысловые особенности входных данных по сравнению с многими плотными моделями векторизации, которые представляют весь текст одним вектором. Благодаря более детализированному представлению входа, \texttt{ColBERT} становится мощным инструментом для поиска. Однако это преимущество сопровождается повышенным потреблением ресурсов по сравнению с традиционными плотными моделями --- как по времени обработки, так и по объёму потребляемой памяти.

Несмотря на высокую эффективность \texttt{ColBERT} как поисковой модели, её ограничение по скорости может сделать её менее подходящей для полномасштабного поиска. Поэтому она обычно рекомендуется для повторной сортировки (reranking) небольшого набора уже отобранных примеров, а не для изначального поиска. Простая плотная модель может сначала выбрать от $100$ до $1000$ кандидатов, после чего \texttt{ColBERT} может отсортировать их, поднимая наиболее релевантные результаты наверх.

Для использования мультивекторов необходимо задать функцию, которая будет использоваться для сравнения между матрицами векторов. В настоящее время \textit{Qdrant} поддерживает функцию \textbf{maxSim}, которая определяется как сумма максимальных сходств между каждой парой векторов из двух матриц.

Здесь $N$ --- количество векторов в первой матрице, $M$ --- количество векторов во второй матрице, а \textbf{Sim} --- функция сходства, например, косинусная близость.

$$
\text{score} = \sum_{i=1}^{N} \max_{j=1}^{M} \text{Sim}(\text{vectorA}_i, \text{vectorB}_j)
$$

В данной работе используется модель \texttt{jinaai/jina-colbert-v2}~\cite{xiao-etal-2024-jina}, реализующая архитектуру \texttt{ColBERT v2}. Она создаёт матричное представление текста размерностью $128$ на токен, обладает $559$ миллионами параметров и поддерживает мультиязычный ввод, включая русский язык. Для использования модели применяется библиотека \textit{fastembed} от \textit{Qdrant}, а сама векторная база данных поддерживает загрузку, хранение и сравнение таких матричных представлений, что обеспечивает их эффективное применение в задачах семантического поиска.

\subsection{Search}
\label{embedding-search}

В современных системах поиска на основе эмбеддингов основное внимание уделяется качеству извлечения релевантной информации из больших текстовых коллекций. В данной главе рассматриваются два основных подхода к реализации поиска: поиск на основе одной модели и гибридный поиск, сочетающий разные источники для повышения качества результатов.

Стандартный поиск предполагает использование модели, которая кодирует как запрос, так и документы в общее векторное пространство. Поиск производится с помощью метрик близости (например, косинусного расстояния) между эмбеддингами. Этот подход эффективен по скорости и хорошо масштабируется, однако может быть не самым точным.

Для улучшения качества поиска применяется гибридный подход, объединяющий преимущества разных стратегий. Он включает в себя три основных метода:

\begin{samepage}
\begin{itemize}
    \setlength\itemsep{0pt}
    \item Fusion
    \item Multistage search
    \item Reranking
\end{itemize}
\end{samepage}


Далее в этой главе подробно рассматриваются особенности и реализация каждого из перечисленных методов, включая их преимущества, недостатки и результаты тестов.

\subsubsection{Стандартный поиск по векторам}

В стандартной конфигурации поиска каждая модель кодирует текст пользовательского запроса в векторное представление. Далее этот вектор сравнивается с эмбеддингами отзывов в базе данных с помощью метрики близости. Система возвращает топ-$K$ наиболее близких по смыслу отзывов, которые затем используются для вычисления метрик качества. Результаты бенчмарка, описанного в разделе~\ref{retrieval-bench} приведены в таблице~\ref{table:standard-search}.



Проведённый бенчмарк моделей в стандартной конфигурации векторного поиска выявил значительные различия как в качестве семантического сопоставления, так и в производительности по времени. Модели семейства \texttt{intfloat/multilingual-e5} стабильно демонстрировали высокие значения по всем метрикам качества. Модель \texttt{sergeyzh/BERTA}, несмотря на сравнительно небольшое число параметров, показала результаты, сопоставимые с более ресурсоёмкими моделями, что делает её эффективным решением в условиях ограниченных вычислительных ресурсов. Модель \texttt{ai-forever/ru-en-RoSBERTa} продемонстрировала средние показатели, без существенного превосходства ни по качеству, ни по скорости. Метод \texttt{BM25}, не являясь нейросетевой моделью, обеспечил конкурентное качество при минимальном времени выполнения. Модель \texttt{jinaai/jina-colbert-v2} достигла наивысших значений метрик, однако её время работы значительно превышает показатели остальных участников. Все остальные протестированные модели показали значительно более низкое качество по сравнению с перечисленными.

\subsubsection{Hybrid search}

Гибридный поиск (hybrid search) --- это комбинированный подход, объединяющий различные методы поиска. Одновременное использование разнообразных моделей позволяет учитывать различия в языковых доменах (русский и мультиязычный корпус), а также выбирать оптимальный баланс между качеством и вычислительными затратами.

\paragraph{Fusion}
% https://qdrant.tech/documentation/concepts/hybrid-queries/#hybrid-search
% https://qdrant.tech/articles/hybrid-search/#fusion-vs-reranking
% упомянуть два эксперимента
% один из них используется в финальной версии приложения

Один из наиболее распространённых подходов к поиску с использованием различных векторных представлений заключается в объединении результатов запросов, соответствующих каждому из представлений, в единый итоговый результат. Такая стратегия особенно актуальна, например, в задачах текстового поиска, где полезно совмещать плотные (dense) и разреженные (sparse) векторы, чтобы одновременно учитывать как семантическое сходство, так и точное совпадение по ключевым словам. Для этого обычно требуется нормализация оценок, потому что результаты, полученные различными моделями, могут быть в разных числовых диапазонах. После этого используется формула, которая берёт меры релевантности и вычисляет итоговый балл, который затем используется для переранжирования документов.

При использовании нескольких моделей векторного поиска возникает проблема несопоставимости их оценок (скоров). Это связано с тем, что каждая модель может иметь собственное распределение значений близости: например, сходство 0.7 при использовании эмбеддингов одной модели может означать высокую релевантность, тогда как в другой --- быть вполне типичной и не указывать на что-то особенное. Поэтому простое объединение скоров не даёт корректного результата --- требуется метод, учитывающий различия в шкалах оценок.

Система Qdrant в настоящее время реализует два метода объединения результатов из нескольких запросов. Первый --- \textbf{Reciprocal Rank Fusion (RRF)} --- основан на анализе позиций документов в списках результатов по каждому запросу. Он усиливает влияние документов, которые занимают высокие позиции сразу в нескольких списках, что позволяет более эффективно агрегировать информацию из разных источников и получать более релевантные ответы. Второй метод --- \textbf{Distribution-Based Score Fusion (DBSF)} --- нормализует оценки (scores) для каждого запроса с использованием среднего значения и интервала, определённого как $\mu \pm 3\sigma$, после чего суммирует оценки одной и той же точки (документа) по всем запросам.

Мы провели два эксперимента с использованием Fusion Search и метода RRF. В первом эксперименте были объединены четыре модели, показавшие наилучшие результаты в индивидуальном поиске: \texttt{sergeyzh/BERTA}, \texttt{intfloat/multilingual-e5-large}, \texttt{ai-forever/ru-en-RoSBERTa}, \texttt{sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2}. Во втором эксперименте были объединены три модели различных типов: плотная модель для русского языка \texttt{sergeyzh/BERTA}, мультиязычная модель \texttt{intfloat/multilingual-e5-small}, а также разреженная модель \texttt{BM25}. Такой подход направлен на повышение разнообразия ответов за счёт использования моделей с разной природой представления информации. Результаты бенчмарка представлены в таблице \ref{tab:hybrid_search_results}. Оба подхода сравнимы по качеству, но 4 лучшие модели сильно уступают по времени работы.

\begin{table}[h]
\small
\centering
\caption{Результаты бенчмарка моделей для гибридного поиска}
\label{tab:hybrid_search_results}
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline
\textbf{Эксперимент} & \textbf{map@1} & \textbf{map@3} & \textbf{map@5} & \textbf{map@10} & \textbf{map@20} & \textbf{Длительность (сек)} \\
\hline
Топ-4 одиночные модели & \textbf{0.4255} & \textbf{0.5160} & 0.5160 & 0.4826 & 0.4826 & 31.9724 \\
3 модели разной природы & \textbf{0.4255} & 0.5124 & \textbf{0.5235} & \textbf{0.4970} & \textbf{0.4637} & \textbf{10.5266} \\
\hline
\end{tabular}
\end{table}

\paragraph{Multi-stage search}
% https://qdrant.tech/documentation/concepts/hybrid-queries/#multi-stage-queries

Во многих задачах векторного поиска использование более длинных и точных векторных представлений позволяет добиться лучших результатов, однако это сопровождается увеличением вычислительных затрат. Эту проблему позволяет эффективно решать многоступенчатый (multi-stage) подход к поиску, при котором этапы различаются по вычислительной стоимости и точности.

На первом этапе используется более простая и дешёвая модель для отбора большого количества кандидатов (например, топ-1000). Затем на втором этапе эти кандидаты переоцениваются с помощью более точной, но вычислительно затратной модели, чтобы выбрать итоговые топ-k (например, топ-20) результатов.



Современные методы переранжирования используют более мощные модели, такие как \texttt{ColBERT}, которые реализуют подход позднего взаимодействия (late interaction). В отличие от классических плотных моделей, которые сравнивают запрос и документ как целостные векторы, \texttt{ColBERT} работает на уровне токенов, сохраняя контекстуализированные представления слов и вычисляя схожесть на более детальном уровне. Это позволяет существенно повысить чувствительность модели к смысловым нюансам.

В рамках данной работы был реализован следующий подход к переранжированию: на первом этапе с помощью модели \texttt{BM25} и одной из плотных моделей извлекались по 40 наиболее релевантных документов. Эти два списка объединялись в общий пул из 80 кандидатов. На втором этапе применялась модель \texttt{ColBERT}, которая выполняла переоценку релевантности этих документов относительно исходного запроса. Итоговый результат формировался путём выбора наиболее релевантных объектов по результатам \texttt{ColBERT}. Такой подход позволил объединить скорость начального поиска с точностью продвинутой модели переранжирования, что подтверждается экспериментальными результатами, приведёнными в таблице \ref{table:reranking_results}.

Внедрение этапа переранжирования с использованием модели \texttt{ColBERT} позволило значительно повысить качество поиска для всех моделей, включая те, что ранее показывали слабые результаты. В итоге результаты всех моделей выровнялись и стали более сопоставимыми по качеству. Однако это улучшение сопровождалось заметным увеличением времени обработки запросов за счёт вычислительной сложности \texttt{ColBERT}.
