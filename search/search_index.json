{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 Getting started","text":""},{"location":"#overview","title":"Overview","text":"<p>Travel Agent is a Trip Planning Assistant powered by Retrieval-Augmented Generation (RAG) technology. The system utilizes the Yandex Geo Reviews 2023 dataset to provide location-aware recommendations for places, businesses, and services.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<ul> <li>Data Pipeline: Prepares and analyzes the Yandex Geo Reviews dataset</li> <li>Embedding Scripts: Implements comparsion of different embedding models for Russian language</li> </ul>"},{"location":"#getting-started_1","title":"Getting Started","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.13</li> <li>DVC for data version control</li> <li>AWS CLI configured for Yandex Cloud</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/miem-refugees/travel-agent.git\ncd travel-agent\n\n# Create a virtual environment with uv\nuv venv\n\n# Install dependencies\nuv sync\n\n# Install dev dependencies\nuv sync --dev\n</code></pre>"},{"location":"#data-preparation","title":"Data Preparation","text":"<p>The project uses DVC to manage the data pipeline:</p> <pre><code># single command for all pipeline:\ndvc repro\n</code></pre>"},{"location":"#embedding-benchmark-results","title":"Embedding Benchmark Results","text":"<p>We've benchmarked several multilingual embedding models on our dataset to measure retrieval performance. The key metric we use is Mean Average Precision (MAP) at different k values.</p>"},{"location":"#mapk-results","title":"MAP@k Results","text":"experiment map@1 map@3 map@5 map@10 map@20 benchmark_duration_sec embedding_dim num_params 0 cointegrated/rubert-tiny2 0.12766 0.18617 0.173848 0.168606 0.157489 3.98638 312 29M 1 DeepPavlov/rubert-base-cased-sentence 0.212766 0.26773 0.284515 0.272984 0.244167 2.73323 768 178M 2 ai-forever/sbert_large_nlu_ru 0.212766 0.271277 0.274232 0.269268 0.240998 3.70873 1024 427M 3 ai-forever/sbert_large_mt_nlu_ru 0.276596 0.356383 0.345952 0.318414 0.298798 3.64512 1024 427M 4 sentence-transformers/distiluse-base-multilingual-cased-v1 0.297872 0.397163 0.404728 0.367698 0.344475 3.07567 512 135M 5 sentence-transformers/distiluse-base-multilingual-cased-v2 0.191489 0.285461 0.286909 0.288297 0.272745 3.12951 512 135M 6 sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 0.361702 0.453901 0.446188 0.419447 0.386504 3.38915 384 118M 7 sentence-transformers/paraphrase-multilingual-mpnet-base-v2 0.382979 0.420213 0.394178 0.377136 0.361083 3.73736 768 278M 8 intfloat/multilingual-e5-large 0.425532 0.5 0.49276 0.468168 0.450785 4.88641 1024 560M 9 intfloat/multilingual-e5-base 0.404255 0.496454 0.513505 0.477439 0.443799 4.3108 768 278M 10 intfloat/multilingual-e5-small 0.425532 0.512411 0.514953 0.476494 0.439935 4.35427 384 118M 11 ai-forever/ru-en-RoSBERTa 0.361702 0.452128 0.472518 0.471765 0.446313 5.38333 1024 405M 12 sergeyzh/BERTA 0.425532 0.507092 0.5151 0.500048 0.473414 3.0437 768 128M 13 Qdrant/bm25 0.404255 0.496454 0.483481 0.475132 0.446098 0.140611 - - 14 jinaai/jina-colbert-v2 0.425532 0.51773 0.52896 0.491759 0.461816 12.2201 128 559M 15 cointegrated/rubert-tiny2+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.425532 0.542553 0.547754 0.514325 0.485871 13.714 - - 16 DeepPavlov/rubert-base-cased-sentence+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.510638 0.599291 0.582388 0.540685 0.497808 14.607 - - 17 ai-forever/sbert_large_nlu_ru+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.489362 0.601064 0.58753 0.539977 0.496107 13.0974 - - 18 ai-forever/sbert_large_mt_nlu_ru+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.425532 0.585106 0.592435 0.540853 0.490978 12.9831 - - 19 sentence-transformers/distiluse-base-multilingual-cased-v1+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.533688 0.544297 0.513253 0.477142 12.1212 - - 20 sentence-transformers/distiluse-base-multilingual-cased-v2+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.556738 0.555201 0.519752 0.491958 12.2971 - - 21 sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.425532 0.54078 0.555171 0.518528 0.48477 13.2642 - - 22 sentence-transformers/paraphrase-multilingual-mpnet-base-v2+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.583333 0.56977 0.525699 0.494034 13.448 - - 23 intfloat/multilingual-e5-large+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.528369 0.520715 0.510914 0.479422 15.2014 - - 24 intfloat/multilingual-e5-base+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.425532 0.556738 0.553251 0.517662 0.478473 13.8399 - - 25 intfloat/multilingual-e5-small+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.537234 0.547252 0.510803 0.474394 13.8324 - - 26 ai-forever/ru-en-RoSBERTa+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.569149 0.56513 0.527441 0.486501 16.7176 - - 27 sergeyzh/BERTA+Qdrant/bm25_reranking_jinaai/jina-colbert-v2 0.446809 0.533688 0.531058 0.505956 0.467606 13.7417 - - 28 multi_stage_1000_Qdrant/bm25_top_k_cointegrated/rubert-tiny2 0.170213 0.297872 0.306619 0.308356 0.284675 2.9336 - - 29 multi_stage_1000_Qdrant/bm25_top_k_DeepPavlov/rubert-base-cased-sentence 0.234043 0.35461 0.356856 0.359375 0.330505 2.79 - - 30 multi_stage_1000_Qdrant/bm25_top_k_ai-forever/sbert_large_nlu_ru 0.234043 0.329787 0.334929 0.329854 0.324031 4.31773 - - 31 multi_stage_1000_Qdrant/bm25_top_k_ai-forever/sbert_large_mt_nlu_ru 0.382979 0.437943 0.452985 0.431871 0.40207 3.85614 - - 32 multi_stage_1000_Qdrant/bm25_top_k_sentence-transformers/distiluse-base-multilingual-cased-v1 0.446809 0.514184 0.500739 0.471549 0.437482 3.61652 - - 33 multi_stage_1000_Qdrant/bm25_top_k_sentence-transformers/distiluse-base-multilingual-cased-v2 0.361702 0.45922 0.456501 0.418857 0.404294 3.06401 - - 34 multi_stage_1000_Qdrant/bm25_top_k_sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 0.489362 0.542553 0.514923 0.503647 0.465368 3.8264 - - 35 multi_stage_1000_Qdrant/bm25_top_k_sentence-transformers/paraphrase-multilingual-mpnet-base-v2 0.382979 0.45922 0.460284 0.456012 0.433776 4.18046 - - 36 multi_stage_1000_Qdrant/bm25_top_k_intfloat/multilingual-e5-large 0.404255 0.501773 0.505467 0.492915 0.471671 5.09563 - - 37 multi_stage_1000_Qdrant/bm25_top_k_intfloat/multilingual-e5-base 0.425532 0.54078 0.532417 0.499876 0.468945 4.22179 - - 38 multi_stage_1000_Qdrant/bm25_top_k_intfloat/multilingual-e5-small 0.553191 0.615248 0.601241 0.56224 0.509358 4.52473 - - 39 multi_stage_1000_Qdrant/bm25_top_k_ai-forever/ru-en-RoSBERTa 0.425532 0.501773 0.504285 0.491842 0.460174 5.51846 - - 40 multi_stage_1000_Qdrant/bm25_top_k_sergeyzh/BERTA 0.404255 0.514184 0.535786 0.520057 0.487631 2.99704 - - 41 hybrid_search_top_models 0.425532 0.515957 0.515957 0.482628 0.482628 31.9724 - - 42 hybrid_search_top_models_2 0.425532 0.512411 0.523522 0.497036 0.46367 10.5266 - - 43 hybrid_search_top_models_3 0.468085 0.546099 0.525798 0.493025 0.455922 19.1039 - -"},{"location":"#retrieval-strategies","title":"Retrieval Strategies","text":"<p>The project compares:</p> <ul> <li>Dense Retrieval: Using vector embeddings to find semantically similar content</li> <li>Sparse Retrieval: Using BM25 and SPLADE for keyword-based retrieval</li> <li>Hybrid Retrieval: Combining dense and sparse approaches</li> <li>Re-ranking: Using cross-encoders or LLM-based re-ranking to refine results</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"docs/","title":"\ud83d\udcda Docs guide","text":"<p>How to work with documentation</p>"},{"location":"docs/#setup","title":"Setup","text":"<p>To work with the documentation, you'll need to install the documentation dependencies:</p> <pre><code># Install documentation dependencies\nuv sync --group docs\n</code></pre>"},{"location":"docs/#development","title":"Development","text":""},{"location":"docs/#local-development-server","title":"Local Development Server","text":"<p>To preview the documentation locally while editing:</p> <pre><code>mkdocs serve\n</code></pre> <p>This will start a development server at http://127.0.0.1:8000 that automatically refreshes when you make changes to the documentation files.</p>"},{"location":"docs/#adding-new-pages","title":"Adding New Pages","text":"<p>To add a new page to the documentation create a Markdown file in the appropriate directory under <code>docs/</code></p>"},{"location":"docs/#adding-images-and-assets","title":"Adding Images and Assets","text":"<p>Store images and other assets in the <code>docs/assets/</code> directory:</p> <pre><code>docs/assets/\n\u251c\u2500\u2500 images/            # For screenshots and diagrams\n\u251c\u2500\u2500 diagrams/          # For architectural diagrams\n\u2514\u2500\u2500 examples/          # For example files\n</code></pre> <p>Reference images in your Markdown using relative paths:</p> <pre><code>![Database Schema](../assets/images/database-schema.png)\n</code></pre>"},{"location":"docs/#building","title":"Building","text":"<p>To build a static version of the documentation:</p> <pre><code>mkdocs build\n</code></pre>"},{"location":"docs/#deployment","title":"Deployment","text":"<p>The documentation is automatically deployed when changes are pushed to the main branch. You can also manually deploy:</p> <pre><code># Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre>"},{"location":"links/","title":"\ud83d\udd17 Useful Links","text":""},{"location":"links/#project-main-points","title":"Project main points:","text":"<ul> <li>EDA notebook: notebooks/eda.ipynb</li> <li>Embedding benchs notebooks: notebooks/embedding_bench_draft.ipynb</li> <li>RAG demo with smolagents notebook: notebooks/smolagents.ipynb</li> <li>Parquet-data upload to qdrant script: scripts/python-qdrant-upload</li> <li>Main app entrypoint: travel_agent/app.py</li> </ul>"},{"location":"links/#embedding","title":"Embedding","text":"<ul> <li>Step-by-Step Guide to Choosing the Best Embedding Model for Your Application</li> <li>\ud83e\udd17 HuggingFace text embedding models</li> <li>https://huggingface.co/spaces/mteb/leaderboard</li> <li>\u0415\u0441\u043b\u0438 \u0441\u043f\u043b\u0438\u0442\u0438\u0442\u044c \u0438 \u043f\u043e\u0442\u043e\u043c \u044d\u043d\u043a\u043e\u0434\u0438\u0442\u044c \u0442\u043e \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u0445\u0443\u0436\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0447\u0435\u043c \u0435\u0441\u043b\u0438 \u0441\u0440\u0430\u0437\u0443 \u0437\u0430\u044d\u043d\u043a\u043e\u0434\u0438\u0442\u044c</li> <li>SPLADE \u043d\u0435 \u043d\u0430\u0448\u0435\u043b \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u0440\u0443\u0441\u0441\u043a\u043e\u0433\u043e \u044f\u0437\u044b\u043a\u0430</li> <li>\u041f\u0440\u043e\u0431\u0443\u044e BM25</li> <li>BM25 \u043d\u043e\u0440\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043d\u043e \u043d\u0430\u0445\u043e\u0434\u0438\u0442 \u0442\u043e\u0447\u043d\u044b\u0435 \u043f\u043e\u0445\u043e\u0436\u0438\u0435 \u0442\u0435\u0440\u043c\u0438\u043d\u044b</li> </ul>"},{"location":"links/#similar-projects","title":"Similar projects","text":"<ul> <li>https://www.reddit.com/r/AI_travel_tips/comments/1edaay2/list_of_ai_travel_planners/</li> <li>https://www.reddit.com/r/SwiftUI/comments/18zmk43/travel_agent_with_ai_llm_using_mixtral_7x8b/</li> </ul>"},{"location":"links/#escalidraw","title":"Escalidraw","text":"<p>https://excalidraw.com/#room=b7046b81e2eecb5354a2,aCkG4wr2nofGPfRqdHRvrA</p>"},{"location":"links/#pre-thesis-defense-presentation","title":"Pre-thesis defense presentation","text":"<p>https://docs.google.com/presentation/d/1cbrVxJIIKTh38mp1etvbBPb7Keg2Lahpx7-37UEfr4Y/edit#slide=id.g3555e3fe151_0_40 https://docs.google.com/spreadsheets/d/10958H5GfqaMmOUCkSUZNHDEb1jerYGgfISlm4z9hGsY/edit?gid=1128803509#gid=1128803509 https://docs.google.com/presentation/d/1gCLtSCC5JiqceMxcvRixxp0AmyPrerR-1WfEp5pbqCE/edit#slide=id.g353fd7a5444_1_6</p>"},{"location":"links/#other","title":"Other","text":"<ul> <li>Project brainstorm miro</li> </ul>"},{"location":"rag/","title":"RAG Implementation","text":"<p>Retrieval-Augmented Generation</p>"},{"location":"rag/#overview","title":"Overview","text":"<p>The RAG system combines semantic search capabilities with a language model to provide accurate and relevant information about travel destinations and establishments based on user reviews. The system uses vector embeddings to find semantically similar reviews and then uses a language model to generate natural language responses.</p>"},{"location":"rag/#components","title":"Components","text":""},{"location":"rag/#1-embedding-model","title":"1. Embedding Model","text":"<p>The system uses the <code>intfloat/multilingual-e5-base</code> as most basic efficient model for generating embeddings. This model is particularly well-suited for multilingual text and provides high-quality semantic representations.</p> <p>Key features: - Supports multiple languages - Efficient base model architecture - Good performance on semantic similarity tasks</p>"},{"location":"rag/#2-vector-database","title":"2. Vector Database","text":"<p>The system uses Qdrant as the vector database to store and retrieve embeddings. Each review is stored with the following metadata: - Review text (vectorized) - Name - Rubrics - Rating (1-5) - Address</p>"},{"location":"rag/#3-search-tool","title":"3. Search Tool","text":"<p>The <code>TravelReviewQueryTool</code> implements the core retrieval functionality with the following features:</p> <ul> <li>Semantic search using embeddings</li> <li>Filtering capabilities:</li> <li>Minimum rating filter</li> <li>Address/location filter</li> <li>Category/rubric filter</li> <li>Configurable retrieval limit (default: 5 results)</li> </ul>"},{"location":"rag/#4-language-model-integration","title":"4. Language Model Integration","text":"<p>The system supports multiple language models through different frameworks using ReAct agent pattern: 1. SmolAgents 2. LangChain</p>"},{"location":"rag/#usage","title":"Usage","text":""},{"location":"rag/#basic-query-example","title":"Basic Query Example","text":"<pre><code># Initialize the search tool\nreview_search_tool = TravelReviewQueryTool(\n    embed_model_name=\"intfloat/multilingual-e5-base\",\n    qdrant_client=qdrant_client,\n    collection_name=\"moskva_intfloat_multilingual_e5_base\"\n)\n\n# Example query\nresults = review_search_tool.forward(\n    query=\"\u043f\u043e\u0441\u043e\u0432\u0435\u0442\u0443\u0439 \u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u044f\u043f\u043e\u043d\u0441\u043a\u0438\u0439 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d \u0432 \u041c\u043e\u0441\u043a\u0432\u0435\",\n    min_rating=4\n)\n</code></pre>"},{"location":"rag/#available-filters","title":"Available Filters","text":"<ol> <li>Query: Natural language query for semantic search</li> <li>Min Rating: Filter establishments by minimum rating (1-5)</li> <li>Address: Filter by location (city or street)</li> <li>Rubrics: Filter by establishment categories</li> </ol>"},{"location":"rag/#evaluation","title":"Evaluation","text":"<p>The system includes evaluation capabilities to measure performance:</p> <ol> <li>Relevancy Evaluation</li> <li>Uses Gemini model for evaluation</li> <li>Measures if retrieved results are relevant to the query</li> <li> <p>Provides relevancy scores and explanations</p> </li> <li> <p>Hallucination Detection</p> </li> <li>Evaluates if generated responses contain factual information</li> <li>Uses predefined templates for consistency</li> </ol>"},{"location":"rag/#performance-metrics","title":"Performance Metrics","text":"<p>The system has been evaluated with the following metrics: - Mean relevancy score: ~0.93 - High consistency in providing relevant results</p>"},{"location":"rag/#best-practices","title":"Best Practices","text":"<ol> <li>Query Formulation</li> <li>Use natural language queries</li> <li>Be specific about requirements</li> <li> <p>Include location when relevant</p> </li> <li> <p>Response Generation</p> </li> <li>Don't repeat entire review text</li> <li>Summarize key points</li> <li> <p>Focus on relevant information</p> </li> <li> <p>Error Handling</p> </li> <li>Handle cases when no results are found</li> <li>Provide helpful feedback to users</li> <li>Use appropriate fallback strategies</li> </ol>"},{"location":"rag/#future-improvements","title":"Future Improvements","text":"<ol> <li>Model Enhancements</li> <li>Experiment with different embedding models</li> <li>Fine-tune models on travel-specific data</li> <li> <p>Implement hybrid search strategies</p> </li> <li> <p>Feature Additions</p> </li> <li>Add more sophisticated filtering options</li> <li>Implement result ranking improvements</li> <li> <p>Add support for more languages</p> </li> <li> <p>Evaluation</p> </li> <li>Expand evaluation metrics</li> <li>Add more comprehensive testing</li> <li>Implement automated quality checks</li> </ol>"}]}